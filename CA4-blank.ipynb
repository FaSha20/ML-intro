{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:blue;font-size:20px;\"align=\"right\">فاطمه شاه حسینی</H2>\n",
    " \n",
    " <H2 style=\"color:blue;font-size:20px;\"align=\"right\"> 810199440 </H2>\n",
    " <H2 style=\"color:blue;font-size:20px;\"align=\"right\"> (Decision Trees, Classification, Linear Regression, Ensemble Learning)  تمرین کامپیوتری شماره چهار </H2>\n",
    " <H2 style=\"color:green;font-size:20px;\"align=\"right\"> هدف </H2>\n",
    " <H2 style=\"color:black;font-size:15px;\"align=\"right\"> آشنایی با روشهای یادگیری ماشین با کمک کتابخانه های پایتون  </H2>\n",
    " <H2 style=\"color:green;font-size:20px;\"align=\"right\"> توضیح کلی پروژه </H2>\n",
    " <H2 style=\"color:black;font-size:15px;\"align=\"right\">  این پروژه در  4فاز انجام میشود. در فاز صفر بررسی و تجزیه داده ها انجام میشود و در فاز اول پیش پردازش و رگرسیون خطی انجام میدهیم سپس در فاز دوم\n",
    "با استفاده از مدلهای طبقه بندی به پیش بینی میپردازیم و در فاز اخر با روشهای یادگیری تجمعی آشنا میشویم </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F3m_CaH3gXes"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>location</th>\n",
       "      <th>style</th>\n",
       "      <th>house_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>...</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Ranch</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>...</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Victorian</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>...</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Colonial</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080</td>\n",
       "      <td>...</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Cape Cod</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0          id             date   \n",
       "0             0             0           0  7129300520  20141013T000000  \\\n",
       "1             1             1           1  6414100192  20141209T000000   \n",
       "2             2             2           2  5631500400  20150225T000000   \n",
       "3             3             3           3  2487200875  20141209T000000   \n",
       "4             4             4           4  1954400510  20150218T000000   \n",
       "\n",
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  ...  yr_built   \n",
       "0  221900.0         3       1.00       1180.0      5650  ...    1955.0  \\\n",
       "1  538000.0         3       2.25       2570.0      7242  ...       NaN   \n",
       "2  180000.0         2       1.00        770.0     10000  ...    1933.0   \n",
       "3  604000.0         4       3.00       1960.0      5000  ...    1965.0   \n",
       "4  510000.0         3       2.00       1680.0      8080  ...    1987.0   \n",
       "\n",
       "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15   \n",
       "0             0    98178  47.5112 -122.257           1340        5650  \\\n",
       "1          1991    98125  47.7210 -122.319           1690        7639   \n",
       "2             0    98028  47.7379 -122.233           2720        8062   \n",
       "3             0    98136  47.5208 -122.393           1360        5000   \n",
       "4             0    98074  47.6168 -122.045           1800        7503   \n",
       "\n",
       "   location         style  house_age  \n",
       "0  Suburban  Contemporary         67  \n",
       "1  Suburban         Ranch         71  \n",
       "2     Rural     Victorian         89  \n",
       "3     Urban      Colonial         57  \n",
       "4  Suburban      Cape Cod         35  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('./house_data.csv')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.2     21613\n",
       "Unnamed: 0.1     21613\n",
       "Unnamed: 0       21613\n",
       "id               21436\n",
       "date               372\n",
       "price             3625\n",
       "bedrooms            15\n",
       "bathrooms           32\n",
       "sqft_living        967\n",
       "sqft_lot          9782\n",
       "floors               7\n",
       "waterfront           2\n",
       "view                 5\n",
       "condition            5\n",
       "grade               13\n",
       "sqft_above         946\n",
       "sqft_basement      305\n",
       "yr_built           117\n",
       "yr_renovated        70\n",
       "zipcode             70\n",
       "lat               5034\n",
       "long               752\n",
       "sqft_living15      777\n",
       "sqft_lot15        8689\n",
       "location             3\n",
       "style                5\n",
       "house_age          116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.Series({c: len(ds[c].unique()) for c in ds})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> ساختار کلی داده </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"fonts/css/fonts.css\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>...</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>house_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21613.00000</td>\n",
       "      <td>21613.00000</td>\n",
       "      <td>21613.00000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>18528.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>18530.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21184.000000</td>\n",
       "      <td>18531.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10806.00000</td>\n",
       "      <td>10806.00000</td>\n",
       "      <td>10806.00000</td>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.401822e+05</td>\n",
       "      <td>3.367464</td>\n",
       "      <td>2.111900</td>\n",
       "      <td>2077.569031</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.492903</td>\n",
       "      <td>...</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>292.121082</td>\n",
       "      <td>1970.896714</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "      <td>50.994864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6239.28002</td>\n",
       "      <td>6239.28002</td>\n",
       "      <td>6239.28002</td>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.673622e+05</td>\n",
       "      <td>0.943028</td>\n",
       "      <td>0.780697</td>\n",
       "      <td>953.971679</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.538562</td>\n",
       "      <td>...</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.637777</td>\n",
       "      <td>29.406420</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "      <td>29.373411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-33323.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5403.00000</td>\n",
       "      <td>5403.00000</td>\n",
       "      <td>5403.00000</td>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10806.00000</td>\n",
       "      <td>10806.00000</td>\n",
       "      <td>10806.00000</td>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16209.00000</td>\n",
       "      <td>16209.00000</td>\n",
       "      <td>16209.00000</td>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21612.00000</td>\n",
       "      <td>21612.00000</td>\n",
       "      <td>21612.00000</td>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.2  Unnamed: 0.1   Unnamed: 0            id         price   \n",
       "count   21613.00000   21613.00000  21613.00000  2.161300e+04  2.161300e+04  \\\n",
       "mean    10806.00000   10806.00000  10806.00000  4.580302e+09  5.401822e+05   \n",
       "std      6239.28002    6239.28002   6239.28002  2.876566e+09  3.673622e+05   \n",
       "min         0.00000       0.00000      0.00000  1.000102e+06  7.500000e+04   \n",
       "25%      5403.00000    5403.00000   5403.00000  2.123049e+09  3.219500e+05   \n",
       "50%     10806.00000   10806.00000  10806.00000  3.904930e+09  4.500000e+05   \n",
       "75%     16209.00000   16209.00000  16209.00000  7.308900e+09  6.450000e+05   \n",
       "max     21612.00000   21612.00000  21612.00000  9.900000e+09  7.700000e+06   \n",
       "\n",
       "           bedrooms     bathrooms   sqft_living      sqft_lot        floors   \n",
       "count  21613.000000  21613.000000  18528.000000  2.161300e+04  18530.000000  \\\n",
       "mean       3.367464      2.111900   2077.569031  1.510697e+04      1.492903   \n",
       "std        0.943028      0.780697    953.971679  4.142051e+04      0.538562   \n",
       "min       -5.000000     -5.000000 -33323.000000  5.200000e+02      1.000000   \n",
       "25%        3.000000      1.750000   1430.000000  5.040000e+03      1.000000   \n",
       "50%        3.000000      2.250000   1920.000000  7.618000e+03      1.500000   \n",
       "75%        4.000000      2.500000   2550.000000  1.068800e+04      2.000000   \n",
       "max       33.000000      8.000000  13540.000000  1.651359e+06      3.500000   \n",
       "\n",
       "       ...    sqft_above  sqft_basement      yr_built  yr_renovated   \n",
       "count  ...  21613.000000   21184.000000  18531.000000  21613.000000  \\\n",
       "mean   ...   1788.390691     292.121082   1970.896714     84.402258   \n",
       "std    ...    828.090978     442.637777     29.406420    401.679240   \n",
       "min    ...    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%    ...   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%    ...   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%    ...   2210.000000     560.000000   1996.000000      0.000000   \n",
       "max    ...   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15   \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \\\n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652   \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631   \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000   \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000   \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000   \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000   \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000   \n",
       "\n",
       "          house_age  \n",
       "count  21613.000000  \n",
       "mean      50.994864  \n",
       "std       29.373411  \n",
       "min        7.000000  \n",
       "25%       25.000000  \n",
       "50%       47.000000  \n",
       "75%       71.000000  \n",
       "max      122.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 27 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0.2   21613 non-null  int64  \n",
      " 1   Unnamed: 0.1   21613 non-null  int64  \n",
      " 2   Unnamed: 0     21613 non-null  int64  \n",
      " 3   id             21613 non-null  int64  \n",
      " 4   date           21613 non-null  object \n",
      " 5   price          21613 non-null  float64\n",
      " 6   bedrooms       21613 non-null  int64  \n",
      " 7   bathrooms      21613 non-null  float64\n",
      " 8   sqft_living    18528 non-null  float64\n",
      " 9   sqft_lot       21613 non-null  int64  \n",
      " 10  floors         18530 non-null  float64\n",
      " 11  waterfront     21613 non-null  int64  \n",
      " 12  view           21613 non-null  int64  \n",
      " 13  condition      21613 non-null  int64  \n",
      " 14  grade          21613 non-null  int64  \n",
      " 15  sqft_above     21613 non-null  int64  \n",
      " 16  sqft_basement  21184 non-null  float64\n",
      " 17  yr_built       18531 non-null  float64\n",
      " 18  yr_renovated   21613 non-null  int64  \n",
      " 19  zipcode        21613 non-null  int64  \n",
      " 20  lat            21613 non-null  float64\n",
      " 21  long           21613 non-null  float64\n",
      " 22  sqft_living15  21613 non-null  int64  \n",
      " 23  sqft_lot15     21613 non-null  int64  \n",
      " 24  location       21613 non-null  object \n",
      " 25  style          21613 non-null  object \n",
      " 26  house_age      21613 non-null  int64  \n",
      "dtypes: float64(8), int64(16), object(3)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\">برای هر ویژگی  (missing data) نسبت داده های از دست رفته   </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.2     0.000000\n",
       "Unnamed: 0.1     0.000000\n",
       "Unnamed: 0       0.000000\n",
       "id               0.000000\n",
       "date             0.000000\n",
       "price            0.000000\n",
       "bedrooms         0.000000\n",
       "bathrooms        0.000000\n",
       "sqft_living      0.142738\n",
       "sqft_lot         0.000000\n",
       "floors           0.142646\n",
       "waterfront       0.000000\n",
       "view             0.000000\n",
       "condition        0.000000\n",
       "grade            0.000000\n",
       "sqft_above       0.000000\n",
       "sqft_basement    0.019849\n",
       "yr_built         0.142599\n",
       "yr_renovated     0.000000\n",
       "zipcode          0.000000\n",
       "lat              0.000000\n",
       "long             0.000000\n",
       "sqft_living15    0.000000\n",
       "sqft_lot15       0.000000\n",
       "location         0.000000\n",
       "style            0.000000\n",
       "house_age        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.isnull().sum()/len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> نمودار وابستگی ویژگی های مختلف به ستون هدف  </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '20141013T000000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ds\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m corr \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m corr_with_price \u001b[38;5;241m=\u001b[39m corr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m corr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10059\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10057\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  10058\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 10059\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  10061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10062\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1838\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1840\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1730\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1732\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1794\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1795\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '20141013T000000'"
     ]
    }
   ],
   "source": [
    "ds.drop(['date'], axis=1)\n",
    "corr = ds.corr()\n",
    "corr_with_price = corr['price']\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_without_price = corr_with_price.drop('price')\n",
    "ds_without_price.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">نسبت به بقیه ویژگی ها، وابستگی بیشتری به قیمت خانه دارند (sqft_lot, sqft_above) ویژگی های    </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> نمودار تعداد داده های منحصر به فرد در ویژگی های مرحله قبل  </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ds.hist(column = \"sqft_lot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.hist(column = \"sqft_above\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.hist(column = \"sqft_living\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\">(scatter plot) بررسی  دقیق تر ارتباط ویژگی ها با ستون قیمت با استفاده از     </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = ds['price']\n",
    "\n",
    "# Loop through the other columns and create a scatter plot for each\n",
    "for col in ds.columns:\n",
    "    if col != 'price':\n",
    "        x = ds[col]\n",
    "        plt.scatter(x, y)\n",
    "        plt.ylabel('Price')\n",
    "        plt.xlabel(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Loop through the other columns and create a scatter plot for each\n",
    "for col in ds.columns:\n",
    "    if col != 'price'and col != 'date' and col != 'location' and col != 'style':\n",
    "        x = ds[col]\n",
    "        plt.hexbin(x, y)\n",
    "        plt.ylabel('Price')\n",
    "        plt.xlabel(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> روش های حل مشکل داده های از دست رفته  </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> یک راه حذف ستون با داده های ناقص است. که چون ممکن است ستون ، حاوی ویژگی تاثیرگذاری باشد، حذف آن در ساخت مدل و نتیجه نهایی موثر است و بنابراین این روش \n",
    "بیشتر در مواقعی مفید است که تعداد نواقص یک ستون زیاد باشد</H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">روش بعدی حذف ردیف با نواقص زیاد است</H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> روش دیگر پر کردن ناقصی های ستون ها با میانگین یا مد هر ستون است. که با وجود اینکه روی طیف داده ها تاثیر منفی ندارد ولی می تواند باعث \n",
    " ایجاد تغییر در پراکندگی و واریانس شود و البته امکان دارد دلیل خالی ماندن بعضی خانه ها این باشد که ویژگی های مخصوص آن خانه اشتراکاتی داشتند و به خاطر همان اشتراک از پر کردن\n",
    "    خانه امتناع کرده اند و پر کردن با میانگین عملا صحت داده ها را به خطر می اندازد</H2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> کدام ویژگی ها بیشترین میزان گم شدن دیتا را دارند؟ </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">  مقادیر گمشده دارند و چون داده ها عددی هستند، پر کردن داده های گمشده با مد ستون راه خوبی است yr_built  و sqft_basement و floors و sqft_living در این دیتاست،  </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "# ds.isnull().sum()\n",
    "ds['sqft_living']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> در ویژگی های عددی استاندار کردن و نرمالایز کردن دیتا به چه منظور انجام می شود؟ </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">  استاندارد کردن و نرمالایز کردن دیتا از متداول ترین شیوه های اسکیل کردن هستند که برای یکسان سازی داده ها به کار می روند و \n",
    "هدفشان این است که بتوان داده هایی که تفاوت زیادی با هم دارند را در بازه مشخصی قرار داد و با هم مقایسه کرد</H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> نزمالیزیشن داده ها را طوری تغییر می دهد که بین صفر و یک قرار بگیرند. هر داده منهای مینیمم داده ها تقسیم بر مقدار ماکسیمم منهای مینیمم. </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">استانداردیزیشن داده ها را طوری اسکیل می کند که میانگین، صفر و انحراف از معیار،  یک شود. هر داده منهای میانگین تقسیم بر انحراف معیار کل داده ها می شود </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> اما در شرایطی که توزیع داده ها برای ما مشخص نیست یا می دانیم توزیع به صورت نرمال یا گاوسی نیست بهتر است از این شیوه استفاده کنیم. این روش در الگوریتم هایی که توزیع خاصی برای داده ها در نظر نمی گیرند به کار می آید. مانند  </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">(neural networks و k_nearest neighbors)</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ds.select_dtypes(include=['int64', 'float64']).columns\n",
    "ds[numeric] =(ds[numeric]-ds[numeric].min())/(ds[numeric].max()-ds[numeric].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> در ویژگی های دسته ای استفاده از چه پیش پردازش هایی مفید اند؟ آیا همه داده های دسته ای به این کار نیاز دارند؟ </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">(label encoding, one-hot-encoding)</H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">برای ترین کردن داده های غیرعددی و دسته ای، لازم است دسته های مختلف را با اعداد برچسب گذاری کنیم \n",
    "و یا با استفاده از نمایش وان هات \n",
    "میتوان به تعداد دامنه متغیر بیت تعیین کرد و همه بیت ها به جز بیت مربوط به گزینه موجود در نمونه را صفر قرار داد. همه داده های دسته ای به این تبدیل و کد شدن نیازی ندارند و باید با توجه به نقش هر فیلد جداگانه درباره آن تصمیم گیری کرد </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['location'] = ds['location'].astype('category')\n",
    "ds['location'] = ds['location'].cat.codes\n",
    "\n",
    "ds['style'] = ds['style'].astype('category')\n",
    "ds['style'] = ds['style'].cat.codes\n",
    "\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> امکان حذف بعضی ستون ها وجود دارد؟ </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">بله، مثلا ستون مربوط به ای دی خانه، یا تاریخ هیچ تاثیری بر قیمت خانه ندارند تقریبا منحصر بفرد اند و  برای شناسایی هر خانه استفاده می شوتد</H2>\n",
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> با چه نسبتی و چطور باید داده های تست و ترین را دسته بندی کرد؟ </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">   در اکثر اوقات، بیشتر نمونه ها را به داده ترین اختصاص می دهیم. ولی نسبت مشخصی ندارد و بستگی به تعداد نمونه ها و کلاس ها و مشخصات داده ها دارد. مثلا اگر بخواهیم 1000 داده را با نسبت 80 به 20 به ترین و تست اختصاص دهیم، باید به 20 درصد دیتا را به طور رندوم جدا کنیم برای تست و بقیه را به ترین کردن مدل اختصاص دهیم   </H2>\n",
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> دیتای ولیدیشن چیست؟ </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">  برای جلوگیری از اورفیت شدن ترین، هربار مدل ترین شده را روی بخشی از دیتا که همان دیتای ولیدیشن می باشد، امتحان می کنیم، با توجه به نتایج و دقت مدل، مقدار هایپر پارامتر ها را تغییر می دهیم . جاییکه دقت مدل کردن دیتای ولیدیشن برخلاف دیتای ترین، شروع به کاهش کرد، یعنی از آنجا به بعد ، مدل در حال اورفیت شدن است و باید همانجا لرنینگ را متوقف کرد  </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sample(frac=1)\n",
    "n = int(0.8 * len(ds))\n",
    "\n",
    "train_data = ds[:n]\n",
    "test_data = ds[n + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgj-rwNggXe4"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-TMX5-kgXe7"
   },
   "source": [
    "Main form of simple linear regression function: \n",
    "$$f(x) = \\alpha x + \\beta$$\n",
    "\n",
    "here we want to find the intercept($\\alpha$) and slope($\\beta$) by minimizing the derivation of the RSS function:\n",
    "\n",
    "- step 1: Compute RSS of the training data  \n",
    "\n",
    "$$ RSS = \\Sigma (y_i - (\\hat{\\beta} + \\hat{\\alpha} * x_i) )^2 $$\n",
    "\n",
    "- step 2: Compute the derivatives of the RSS function in term of $\\underline{\\alpha}$ and $\\underline{\\beta}$, and set them equal to 0 to find the desired parameters\n",
    "\n",
    "$$ \\frac{\\partial RSS}{\\partial \\beta} = \\Sigma (-f(x_i) + \\hat{\\beta} + \\hat{\\alpha} * x_i) = 0$$\n",
    "$$ \\to \\hat{\\beta} = \\hat{y} - \\hat{\\alpha} \\hat{x} \\to (1)$$\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial RSS}{\\partial \\alpha} = \\Sigma (-2 x_i y_i + 2 \\hat{\\beta} x_i + 2\\hat{\\alpha} x_i ^ 2) = 0 \\to (2)$$\n",
    "\n",
    "$$ (1) , (2) \\to \\hat{\\alpha} = \\frac{\\Sigma{(x_i - \\hat{x})(y_i - \\hat{y})}}{\\Sigma{(x_i - \\hat{x})^2}}\n",
    "$$ \n",
    "$$ \\hat{\\beta} = \\hat{y} - \\hat{\\alpha} \\hat{x}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdPAhX3KgXe9"
   },
   "source": [
    "Based on the formula above, complete this function to compute the parameters of a simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiBbu2fagXfB"
   },
   "outputs": [],
   "source": [
    "def simple_linear_regression(input_feature, output):\n",
    "\n",
    "    # compute the sum of input_feature and output\n",
    "    x_mean = sum(input_feature) / len(input_feature)\n",
    "    y_mean = sum(output) / len(output)\n",
    "    \n",
    "    # compute the product of the output and the input_feature and its sum\n",
    "    numerator_sum , denominator_sum = 0, 0\n",
    "    for i in range(len(input_feature)):\n",
    "        numerator_sum += ( (input_feature[i] - x_mean ) * (output[i] - y_mean) )\n",
    "        denominator_sum += (input_feature[i] - x_mean ) * (input_feature[i] - x_mean )\n",
    "    \n",
    "    # use the formula for the slope\n",
    "    slope = numerator_sum / denominator_sum\n",
    "    \n",
    "    # use the formula for the intercept\n",
    "    intercept = y_mean - slope * x_mean\n",
    "    \n",
    "    return (intercept, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_feature = train_data['sqft_living']\n",
    "price = train_data['price']\n",
    "intercept, slope = simple_linear_regression(best_feature, price)\n",
    "print(\"alpha = \",slope, \", beta = \", intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:red;font-size:25px;\"align=\"right\"> متد های ارزیابی رگرسیون خطی </H2>\n",
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> Residual Sum of Squares (RSS) </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> مجموع مربعات باقیمانده ، یک تکنیک آماری است که برای توصیف تفاوت در واریانس مقادیر مشاهده شده در برابر مقادیر پیش بینی شده استفاده می شود. این معیار خوبی است که می تواند برای تجزیه و تحلیل میزان تناسب مجموعه ای از نقاط داده با مدل واقعی مورد استفاده قرار گیرد. </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\">RSS = ∑ni=1 (yi - f(xi))2</H2>\n",
    "\n",
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> R2 score (R Square) </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> مجموع مربعات ، یک تکنیک آماری است که می گوید چه نسبتی از واریانس در متغیر پاسخ،  می تواند توسط متغیر(های) پیش بینی کننده در مدل توضیح داده شود </H2>\n",
    "<img src=\"rss.png\" width=\"500\" height=\"600\">\n",
    "<img src=\"rss2.png\" width=\"300\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> Mean Squared Error (MSE) </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> این روش برآوردگر (روشی برای تخمین کمیت مشاهده نشده)، میانگین مربعات خطاها را اندازه گیری می کند - یعنی میانگین مجذور اختلاف بین مقادیر برآورد شده و آنچه تخمین زده می شود</H2>\n",
    "<img src=\"mse.png\" width=\"300\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> Root Mean Square Error (RMSE) </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> این متد جذر واریانس باقیمانده ها را نشان می دهد و به ما ایده ای از فاصله متوسط ​​بین مقادیر داده های مشاهده شده و مقادیر داده های پیش بینی شده می دهد </H2>\n",
    "<img src=\"rmse.jpg\" width=\"400\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihT-a1dvgXfE"
   },
   "source": [
    "Now complete this function to predict the value of given data based on the calculated intercept and slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwHcast_gXfF"
   },
   "outputs": [],
   "source": [
    "def get_regression_predictions(input_feature, intercept, slope):\n",
    "\n",
    "    # calculate the predicted values:\n",
    "    predicted_values = slope * input_feature + intercept\n",
    "\n",
    "    return (predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_res = get_regression_predictions(train_data['sqft_living'], intercept, slope)\n",
    "prices = train_data['price']\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    print(\"train result: \", train_res[i])\n",
    "    print(\"real price:   \", prices.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = get_regression_predictions(test_data['sqft_living'], intercept, slope)\n",
    "prices = test_data['price']\n",
    "\n",
    "for i in range(17291, 21612):\n",
    "    print(\"test result: \", test_res[i])\n",
    "    print(\"real price:   \",prices[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgIG_oJggXfF"
   },
   "source": [
    "Now that we have a model and can make predictions let's evaluate our model using Root Mean Square Error (RSME). RMSE is the square root of the mean of the squared differences between the residuals and the residuals is just a fancy word for the difference between the predicted output and the true output.\n",
    "\n",
    "Complete the following function to compute the RSME of a simple linear regression model given the input_feature, output, intercept and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFSnPatrgXfG"
   },
   "outputs": [],
   "source": [
    "def get_root_mean_square_error(predicted_values , output):\n",
    "    # TO DO:\n",
    "\n",
    "    # Compute the residuals (since we are squaring it doesn't matter which order you subtract)\n",
    "    residuals = output - predicted_values\n",
    "\n",
    "    # square the residuals and add them up\n",
    "    sum = 0\n",
    "    for r in residuals:\n",
    "        sum += r*r\n",
    "\n",
    "    # find the mean of the above phrase\n",
    "    MSE = sum / len(output)\n",
    "   \n",
    "    # calculate the root\n",
    "    RMSE = math.sqrt(MSE)\n",
    "\n",
    "    return(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY_28bJFgXfH"
   },
   "source": [
    "AS you might guessed, the RMSE has no bound and it is not easy to find out the percentage of fitting the model into data with it. instead, we use R2 score. The R2 score is calculated by comparing the sum of the squared differences between the actual and predicted values of the dependent variable to the total sum of squared differences between the actual and mean values of the dependent variable. Matematically, the R2 score formula is shown as follows:\n",
    "\n",
    "$$R^2 = 1 - \\frac{SSres}{SStot} = 1 - \\frac{\\sum_{i=1}^{n} (y_{i,true} - y_{i,pred})^2}{\\sum_{i=1}^{n} (y_{i,true} - \\bar{y}_{true})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qpx03GxgXfH"
   },
   "source": [
    "In this step, complete the following function to calculate the R2 score of a given input_feature, output, intercept, and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5hIou1AgXfJ"
   },
   "outputs": [],
   "source": [
    "def get_r2_score(predicted_values, output):\n",
    "\n",
    "    # compute the residuals (since we are squaring it doesn't matter which order you subtract)\n",
    "    residuals = output - predicted_values\n",
    "    total_res = output - ( sum(output)/len(output) )\n",
    "   \n",
    "    # square the residuals and add them up -> SSres\n",
    "    SSres = 0\n",
    "    for r in residuals:\n",
    "        SSres += r*r\n",
    "\n",
    "    # compute the SStot\n",
    "    SStot = 0\n",
    "    for r in total_res:\n",
    "        SStot += r*r\n",
    "\n",
    "    # compute the R2 score value\n",
    "    R2_score = 1 - SSres / SStot\n",
    "\n",
    "    return(R2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i90h7gugXfJ"
   },
   "source": [
    "Now calculate the fitness of the model and explain the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = train_res\n",
    "output = train_data['price']\n",
    "\n",
    "RMSE_evaluation = get_root_mean_square_error(predicted_values , output)\n",
    "R2score_evaluation = get_r2_score(predicted_values, output)\n",
    "print(RMSE_evaluation)\n",
    "print(R2score_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlpgW1c5gXfK",
    "outputId": "565d94db-ce44-4287-c5ef-6e43107b1b3c"
   },
   "outputs": [],
   "source": [
    "designated_feature_list = ['sqft_living' , 'yr_built' , 'grade' , 'zipcode']\n",
    "output_feature = 'price'\n",
    "\n",
    "for input_feature in designated_feature_list:\n",
    "    #  calculate R2 score and RMSE for each given feature\n",
    "    intercept, slope = simple_linear_regression(train_data[input_feature], train_data[output_feature])\n",
    "    predicted_values = get_regression_predictions(test_data[input_feature], intercept, slope)\n",
    "    RMSE_evaluation = get_root_mean_square_error(test_data[input_feature] , test_data[output_feature])\n",
    "    R2score_evaluation = get_r2_score(predicted_values, test_data[output_feature])\n",
    "    print(input_feature , \": \")\n",
    "    print(\"RMSE_evaluation = \", RMSE_evaluation)\n",
    "    print(\"R2score_evaluation = \", R2score_evaluation)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> همانطور که می بینیم، مقدار ریشه میانگین مربع خطا برای ویژگی اول کمتر و درصد نمونه های درست تشخیص داده شده در آردو بیشتر از سایر ویژگی ها شده که این \n",
    "نشان می دهد، ویژگی اول که بیشترین کانولوشن با قیمت را داشت، بهترین ویژگی است که می تواند قیمت خانه را با توجه به آن پیش بینی کرد</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:red;font-size:25px;\"align=\"right\"> فاز دو - طبقه بندی </H2>\n",
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> اضافه کردن ستون سطح قیمت به دیتاست  </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midian_price = ds['price'].median()\n",
    "prices = []\n",
    "\n",
    "for i in range(len(ds['price'])):\n",
    "    if ds['price'][i] > midian_price:\n",
    "        prices.append(\"HIGH\") \n",
    "    else:\n",
    "        prices.append(\"LOW\")\n",
    "        \n",
    "ds['price_level'] = prices\n",
    "ds = ds.drop(['date', 'price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sample(frac=1)\n",
    "\n",
    "n = int(0.8 * len(ds))\n",
    "\n",
    "train_data = ds[:n]\n",
    "test_data = ds[n + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> Confusion matrix  </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> این ماتریس از چهار خانه تشکیل شده، که داده های تست را برحسب صحت تشخیص توسط مدل، طبقه بندی می کند. خانه اول مربوط به تعداد دیتا  های مربوط به کلاس یک است که توسط مدل به درستی تشخیص داده شده اند، خانه دوم دیتاهایی که به اشتباه در کلاس دو قرار داده شده اند. خانه سوم دیتا هایی که به اشتباه در کلاس اول قرار داده شده اند و خانه چهارم دیتاهایی که به درستی در کلاس دو قرار داده شده اند   </H2>\n",
    "<img src=\"cmat.png\" width=\"400\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltConfusionMatrix(y_test, y_pred , str):\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    clf = ConfusionMatrixDisplay(matrix, display_labels=['type 0', 'type 1'])\n",
    "    clf.plot()\n",
    "    clf.ax_.set(title='Confusion Matrix ' + str, \n",
    "                xlabel='Predicted Value', \n",
    "                ylabel='Actual Value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision Tree\n",
    "\n",
    "X = ds.drop('price_level', axis=1)\n",
    "y = ds['price_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "classifier = DecisionTreeClassifier(criterion= \"gini\", max_depth=10, min_samples_leaf=10, min_samples_split = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "pltConfusionMatrix(y_test, y_pred, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> Grid Search  </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> گرید سرچ تابعی است که با گرفتن داده ترین ، بهترین هایپرپارامتر ها را برای لرنینگ انتخابت می کند تا دچار اورفیت و اندرفیت نشویم و نهایتا به بهبود پرفرمنس منجر می شود </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [1,5,10],\n",
    "    'min_samples_split': [2,6,9],\n",
    "    'min_samples_leaf': [2,5,8,10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree.plot_tree(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN classifier\n",
    "\n",
    "# separate the features and outcome\n",
    "X = ds.drop(['price_level'], axis=1) # all columns except 'outcome'\n",
    "y = ds['price_level'] # only the 'outcome' column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =0)#74\n",
    "\n",
    "# initialize and fit the k-nearest neighbors model\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "  \n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))   \n",
    "pltConfusionMatrix(y_test, y_pred, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression model\n",
    "\n",
    "X = ds.drop('price_level', axis=1)\n",
    "y = ds['price_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)#52, 82,0\n",
    "\n",
    "# create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the model on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "pltConfusionMatrix(y_test, y_pred, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\"> Overfit and Underfit  </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\">  آندرفیت وقتی رخ می دهد که مدل به خوبی ترین نشده و تعداد داده های ترین کم بوده بنابراین مدل ساخته شده،\n",
    "نه روی داده ترین و نه تست به خوبی کار نمی کند. در این صورت می گوییم داده ها بایاس زیاد و واریانس کم دارند</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\">    اور فیت وقتی رخ میدهد که مدل کاملا روی داده ترین ، اموزش دیده و دقیقا خود را با آن (حتی با نویز های آن) منطبق کرده است. \n",
    "بنابراین روی داده ترین با دقت خیلی زیاد کار می کند ولی روی داده ی تست دقت بسیار کمتری دارد. به طوریکه این تفاوت دقت در دو داده قابل توجه است.\n",
    "در این صورت می گوییم داده ها واریانس زیاد و بایاس کم دارند و مدل قابلیت جنریزیشن خود را از دست داده است</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\"> از آنجایی که مدل ، داده ترین را هم به همان دقت داده تست پیش بینی کرده است، یعنی \n",
    "هایپرپارامتر ها به درستی انتخاب شده اند و مدل دچار اورفیت نشده است. همچنین چون مدل به پیش بینی های قابل قبولی داشته است و دقت 89 درصد داشته یعنی دچار اندرفیت هم نشده است</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:25px;\"align=\"right\"> تغییر در پیش پردازش ها   </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN classifier (Change the number of neighbors from 15 to 1000)\n",
    "\n",
    "# separate the features and outcome\n",
    "X = ds.drop(['price_level'], axis=1) \n",
    "y = ds['price_level'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =0)#74\n",
    "\n",
    "# initialize and fit the k-nearest neighbors model\n",
    "knn = KNeighborsClassifier(n_neighbors=1000)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "  \n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))   \n",
    "pltConfusionMatrix(y_test, y_pred, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision Tree\n",
    "\n",
    "X = ds.drop('price_level', axis=1)\n",
    "y = ds['price_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "classifier = DecisionTreeClassifier(criterion= \"gini\", max_depth=2, min_samples_leaf=10, min_samples_split = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "pltConfusionMatrix(y_test, y_pred, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:balck;font-size:20px;\"align=\"right\">همانطور که می بینیم، افزایش تعداد همسایگان در الگوریتم کا ان ان، باعث افت دقت می شود و در الگوریتم درخت جست و جو با کاهش عمق درخت از 10 به 2، مدل دچار اندرفیت شده و دقت آن کاهش می یابد . همچنین با افزایش عمق درخت از 10 به 20، دچار اورفیت شده و دقت مجددا کاهش می یابد.</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:red;font-size:20px;\"align=\"right\"> Ensemble Learning </H2>\n",
    "<H2 style=\"color:green;font-size:15px;\"align=\"right\">  Random Forest </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(newFilmData, n, m, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(newFilmData, target, test_size=0.3, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators = n, min_samples_leaf = m).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_trainPred = clf.predict(X_train)\n",
    "    trainList = accuracy_score(y_test, y_pred)\n",
    "    testList = accuracy_score(y_train, y_trainPred)\n",
    "    return trainList, testList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\">  بررسی هایپرپارامتر ها و تاثیر آنها بر پیش بینی رندوم فارست </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">n_estimators: Number of trees in the forest.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">criterion: The function to measure the quality of a split.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">max_depth: Maximum depth of the tree.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">min_samples_split: Minimum number of samples required to split an internal node.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">min_samples_leaf: Minimum number of samples required to be at a leaf node.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">max_features: Number of features to consider when looking for the best split.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">max_leaf_nodes: Maximum number of leaf nodes.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">bootstrap: Whether or not to sample data with replacement.</H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"left\">n_jobs: Number of jobs to run in parallel. </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = ds.drop(['price_level'], axis=1) \n",
    "y = ds['price_level'] \n",
    "\n",
    "n_estimators = [10, 50, 100, 150, 200]\n",
    "max_depth = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "# Create a 2D array to store the accuracy for each combination of n_estimators and max_depth\n",
    "scores = np.zeros((len(n_estimators), len(max_depth)))\n",
    "for i, n in enumerate(n_estimators):\n",
    "    for j, d in enumerate(max_depth):\n",
    "        # Train the Random Forest model with the current combination of n_estimators and max_depth\n",
    "        clf = RandomForestClassifier(n_estimators=n, max_depth=d)\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Calculate the accuracy for the current combination of n_estimators and max_depth\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        scores[i, j] = accuracy\n",
    "        print(i, j , accuracy)\n",
    "\n",
    "# Plot the results as a heatmap\n",
    "plt.imshow(scores, aspect='auto', origin='lower')\n",
    "plt.xticks(np.arange(len(max_depth)), max_depth)\n",
    "plt.yticks(np.arange(len(n_estimators)), n_estimators)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Number of Estimators')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> n_estimators  </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">  تعداد درختانی که با ویژگی های متفاوت ترین شده و درنهایت بین پیش بینی های آنها رای گیری می شود  </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> max_depth  </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">  بیشترین عمق درخت های تصمیم  </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\">همانطور که درنمودار مشخص است با افزایش عمق درخت ها دقت بالاتر می رود و افزایش تعداد درخت ها تا جایی دقت را افزایش می دهد ولی پس از آن کاهش می یابد  ،  </H2>\n",
    "<H2 style=\"color:red;font-size:20px;\"align=\"right\"> مقایسه رندوم فارست و درخت تصمیم  </H2>\n",
    "<H2 style=\"color:black;font-size:20px;\"align=\"right\">رندوم فارست نتیجه دقیق تری نسبت به درخت تصمیم ساده می دهد. در درخت تصمیم واریانس بالا و بایاس کم است. مخصوصا وقتی عمق درخت را خیلی زیاد کنیم ، مدل تمام جزییات دیتای ترین را یاد میگیرد برای همین بایاس (که نشان دهنده اختلاف پیش بینی و واقعیت نمونه است) کم می شود که منجر میشود خاصیت جنرالیزیشن خود را از دست داده و  دچار اورفیت شود.\n",
    "     به طور برعکس در رندوم فارست، چون بین جوابهای درخت های متعدد رای گیری میشود ، واریانس کم و چون به جزییات نتیجه هر درخت پرداخته نمی شود، بایاس زیاد می شود. اینجا خطری که مدل را تهدید می کند اندرفیت شدن است. ولی درکل همانطور که در نتایج می بینیم،  رندوم فارست پیش بینی دقیق تری دارد .</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:red;font-size:25px;\"align=\"right\">Gradiant Boosting </H2>\n",
    "<H2 style=\"color:balck;font-size:20px;\"align=\"right\">یکی از روش های تقویت کردن دقت یک مدل پیش بینی الگوریتم \"افزایش گرادیان\" است.این الگوریتم چندین یادگیرنده ضعیف را با هم ترکیب و به یادگیرندگان قویتر تبدیل می کند، به این صورت که در آن هر مدل جدید برای به حداقل رساندن تابع ضرر مدل قبلی با استفاده از نزول گرادیان (گرادینت دیسنت)آموزش داده می شود. در هر تکرار، الگوریتم گرادیان تابع ضرر را با توجه به پیش‌بینی‌های مجموعه فعلی محاسبه می‌کند و سپس یک مدل ضعیف جدید را برای به حداقل رساندن این گرادیان آموزش می‌دهد. سپس پیش‌بینی‌های مدل جدید به مجموعه اضافه می‌شود و این فرآیند تا زمانی که یک معیار توقف برآورده شود، تکرار می‌شود </H2>\n",
    "<img src=\"gb.png\" width=\"500\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:25px;\"align=\"right\"> تفاوت گرادیان بوستینگ و رندوم فارست</H2>\n",
    "<H2 style=\"color:balck;font-size:20px;\"align=\"right\">بوستینگ مبتنی بر لرنر های ضعیفی مثل درختان کم عمق است که  بایاس زیاد و واریانس کم دارند. دراین روش تقویت خطا عمدتاً با با تجمیع خروجی مدل ها و با کاهش دادن بایاس انجام میشود\n",
    "از سوی دیگر، رندوم فارست از درختان تصمیم گیری کاملاً رشد یافته استفاده می کند که بایاس کم و واریانس بالا دارند. سپس با کاهش واریانس،  کاهش خطا را انجام میدهد. الگوریتم نمی تواند بایاس را کاهش دهد، بنابراین در ابتدا نیاز به درختان بزرگ و هرس نشده است، به طوری که در ابتدا بایاس تا حد ممکن کم باشد. </H2>\n",
    "<H2 style=\"color:green;font-size:25px;\"align=\"right\">XGboost</H2>\n",
    "<H2 style=\"color:balck;font-size:20px;\"align=\"right\"> یک نوع پیاده سازی درخت تصمیم گرادیانت بوستینگ است که تابع ضرر را به حداقل می رساند. دراین پیاده سازی آموزش به صورت مکرر ادامه می‌یابد و درخت‌های جدیدی اضافه می‌شوند که باقی‌مانده یا خطاهای درخت‌های قبلی را پیش‌بینی می‌کنند و سپس با درخت‌های قبلی ترکیب می‌شوند تا پیش‌بینی نهایی را انجام دهند.  از یک الگوریتم نزولی گرادیان برای به حداقل رساندن لاست ها هنگام افزودن مدل‌های جدید استفاده می‌کند و به تدریج شرایط  بیشتری را به درخت تصمیم اضافه می کند تا یک مدل قوی تر بسازد </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop('price_level', axis=1)\n",
    "y = ds['price_level']\n",
    "y = [(1 if i==\"HIGH\" else 0) for i in y]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "clf=XGBClassifier(max_depth=10, learning_rate=0.1, n_estimators=500, objective='binary:logistic', booster='gbtree')\n",
    " \n",
    "#Creating the model on Training Data\n",
    "XGB = clf.fit(X_train,y_train)\n",
    "pred = XGB.predict(X_test)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print('Accuracy:', accuracy)\n",
    "pltConfusionMatrix(y_test, pred, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [1,3,5,10,50]\n",
    "}\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:balck;font-size:20px;\"align=\"right\">  همانطور که می بینیم با استفاده از الگوریتم گرادیان بوستینگ دقت پیش بینی افزایش یافته است. همچنین از تابع گرید سرچ برای پیدا کردن هایپرپارامتر مربوط به عمق ماکسیمم استفاده کرده ایم </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\">منابع </H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://www.bing.com/search?EID=MBSC&form=BGGCDF&pc=U710&q=which+version+of+scikitlearn+i+have+to+install%3F <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://scikit-learn.org/stable/modules/tree.html <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://medium.datadriveninvestor.com/an-introduction-to-grid-search-ff57adcc0998 <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://www.geeksforgeeks.org/ml-gradient-boosting/ <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://stats.stackexchange.com/questions/173390/gradient-boosting-tree-vs-random-forest#:~:text=Boosting%20is%20based%20on%20weak%20learners%20%28high%20bias%2C,variance%2C%20by%20aggregating%20the%20output%20from%20many%20models%29. <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://www.geeksforgeeks.org/understanding-logistic-regression/ <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://www.geeksforgeeks.org/xgboost/ <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://www.datacamp.com/tutorial/xgboost-in-python <H2>\n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> https://scikit-learn.org/stable/modules/preprocessing.html <H2>\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
